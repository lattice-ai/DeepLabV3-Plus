{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone -b tpu https://github.com/lattice-ai/DeepLabV3-Plus\n%cd DeepLabV3-Plus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git pull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport tensorflow as tf\n\nfrom kaggle_datasets import KaggleDatasets\nfrom deeplabv3plus.datasets import TFRecordDataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('human-segmentation-tfrecords')\nprint(GCS_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_TFRECORDS = tf.io.gfile.glob(\n    os.path.join(\n        GCS_PATH,\n        'human-segmentation-tfrecords/human-segmentation-train/*.tfrec'\n    )\n)\n\nprint('Number of TFRecord Files:', len(TRAIN_TFRECORDS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfrecord_dataset = TFRecordDataset(tfrecords=TRAIN_TFRECORDS,\n                                   image_size=512,\n                                   apply_flips=True,\n                                   apply_jitter=False)\n\ntfrecord_dataset.summary(visualize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from deeplabv3plus.utils import get_strategy\n\nTRAIN_STRATEGY = get_strategy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfrecord_dataset.dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AtrousSpatialPyramidPooling(model_input):\n  dims = tf.keras.backend.int_shape(model_input)\n\n  layer = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3],\n                                                      dims[-2]))(model_input)\n  layer = tf.keras.layers.Conv2D(256, kernel_size=1, padding='same',\n                                 kernel_initializer = 'he_normal')(layer)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  layer = tf.keras.layers.ReLU()(layer)\n  out_pool = tf.keras.layers.UpSampling2D(size = (dims[-3] // layer.shape[1],\n                                               dims[-2] // layer.shape[2]),\n                                        interpolation = 'bilinear')(layer)\n  \n  layer = tf.keras.layers.Conv2D(256, kernel_size = 1,\n                                   dilation_rate = 1, padding = 'same',\n                                   kernel_initializer = 'he_normal',\n                                   use_bias = False)(model_input)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  out_1 = tf.keras.layers.ReLU()(layer)\n\n  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n                                   dilation_rate = 6, padding = 'same', \n                                   kernel_initializer = 'he_normal',\n                                   use_bias = False)(model_input)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  out_6 = tf.keras.layers.ReLU()(layer)\n\n  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n                                   dilation_rate = 12, padding = 'same',\n                                   kernel_initializer = 'he_normal',\n                                   use_bias = False)(model_input)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  out_12 = tf.keras.layers.ReLU()(layer)\n\n  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n                                   dilation_rate = 18, padding = 'same',\n                                   kernel_initializer = 'he_normal',\n                                   use_bias = False)(model_input)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  out_18 = tf.keras.layers.ReLU()(layer)\n\n  layer = tf.keras.layers.Concatenate(axis = -1)([out_pool, out_1,\n                                                    out_6, out_12,\n                                                    out_18])\n\n  layer = tf.keras.layers.Conv2D(256, kernel_size = 1,\n                                   dilation_rate = 1, padding = 'same',\n                                   kernel_initializer = 'he_normal',\n                                   use_bias = False)(layer)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  model_output = tf.keras.layers.ReLU()(layer)\n  return model_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DeeplabV3Plus(nclasses = 20):\n  model_input = tf.keras.Input(shape=(512,512,3))\n  resnet50 = tf.keras.applications.ResNet50(weights = 'imagenet',\n                                            include_top = False,\n                                            input_tensor = model_input)\n  layer = resnet50.get_layer('conv4_block6_2_relu').output\n  layer = AtrousSpatialPyramidPooling(layer)\n  input_a = tf.keras.layers.UpSampling2D(size = (512 // 4 // layer.shape[1],\n                                                 512 // 4 // layer.shape[2]),\n                                          interpolation = 'bilinear')(layer)\n\n  input_b = resnet50.get_layer('conv2_block3_2_relu').output\n  input_b = tf.keras.layers.Conv2D(48, kernel_size = (1,1), padding = 'same',\n                                   kernel_initializer = tf.keras.initializers.he_normal(),\n                                   use_bias = False)(input_b)\n  input_b = tf.keras.layers.BatchNormalization()(input_b)\n  input_b = tf.keras.layers.ReLU()(input_b)\n\n  layer = tf.keras.layers.Concatenate(axis = -1)([input_a, input_b])\n\n  layer = tf.keras.layers.Conv2D(256, kernel_size = 3,\n                                   padding = 'same', activation = 'relu',\n                                   kernel_initializer = tf.keras.initializers.he_normal(),\n                                   use_bias = False)(layer)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  layer = tf.keras.layers.ReLU()(layer)\n  layer = tf.keras.layers.Conv2D(256, kernel_size =3,\n                                   padding = 'same', activation = 'relu',\n                                   kernel_initializer = tf.keras.initializers.he_normal(),\n                                   use_bias = False)(layer)\n  layer = tf.keras.layers.BatchNormalization()(layer)\n  layer = tf.keras.layers.ReLU()(layer)\n  layer = tf.keras.layers.UpSampling2D(size = (512 // layer.shape[1],\n                                               512 // layer.shape[2]),\n                                       interpolation = 'bilinear')(layer)\n  model_output = tf.keras.layers.Conv2D(nclasses, kernel_size = (1,1),\n                                   padding = 'same')(layer)\n  return tf.keras.Model(inputs = model_input, outputs = model_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with TRAIN_STRATEGY.scope():\n    MODEL = DeeplabV3Plus()\n    \n    MODEL.compile(\n        optimizer=tf.keras.optimizers.Adam(\n            learning_rate=0.0001),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=['accuracy']\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(iter(tfrecord_dataset.configured_dataset(batch_size=1)))\n\nMODEL.fit(x, y, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}